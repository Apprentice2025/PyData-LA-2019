{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Pytorch Dataset\n",
    "Using Pytorch's `Dataset` and `DataLoader` we can build a data-serving pipeline to our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import joblib, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pdb\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Geoviews visualization default options\n",
    "H,W, = 250,250\n",
    "opts.defaults(\n",
    "    opts.RGB(height=H, width=W, tools=['hover'], active_tools=['wheel_zoom'], shared_axes=False),\n",
    "    opts.Image(height=H, width=W, tools=['hover'], active_tools=['wheel_zoom'], shared_axes=False),\n",
    "    opts.Image('mask', alpha=0.4),\n",
    "    opts.Points( tools=['hover'], active_tools=['wheel_zoom']),\n",
    "    opts.Curve( tools=['hover'], active_tools=['wheel_zoom'], padding=0.1),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "this_nb_path = Path(os.getcwd())\n",
    "ROOT = this_nb_path.parent\n",
    "SCRIPTS = ROOT/'src'\n",
    "paths2add = [this_nb_path, SCRIPTS]\n",
    "\n",
    "print(\"Project root: \", str(ROOT))\n",
    "print(\"this nb path: \", str(this_nb_path))\n",
    "print('Scripts folder: ', str(SCRIPTS))\n",
    "\n",
    "for p in paths2add:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(str(p), \"added to the path\\n\")\n",
    "        \n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "def f(x):\n",
    "    return x\n",
    "\n",
    "interact(f, x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "---\n",
    "## Import PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### [Optional] Set visible device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# Random seed helper\n",
    "from helpers import random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "IMGNET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMGNET_STD = [0.229, 0.224, 0.225]\n",
    "TRAIN_DATA_DIR = Path('../data/cocolike/train/')\n",
    "TEST_DATA_DIR = Path('../data/cocolike/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## PyTorch Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 1. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import datasets as seg_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Define train and validation datasets without any transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_ds = seg_ds.SegDataset(\n",
    "    ids_file=TRAIN_DATA_DIR/'train_ids.txt', \n",
    "    x_dir=TRAIN_DATA_DIR/'images',\n",
    "    y_dir=TRAIN_DATA_DIR/'segmentations',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 2. Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "Compose transforms each of which will operate on numpy array (3dimensional with order h,w,nC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from model.seg_transforms import TailPadder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Define x,y transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "RANDOM_ROT_DEGREE = 20\n",
    "PAD_OUT_SIZE = 500\n",
    "FILL = 255\n",
    "\n",
    "tr_x_tsfm = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    TailPadder(PAD_OUT_SIZE, fill=FILL),\n",
    "    \n",
    "     # Data augs\n",
    "#      transforms.RandomRotation(RANDOM_ROT_DEGREE, fill=FILL),\n",
    "#      transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0, hue=0),\n",
    "     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=IMGNET_MEAN, std=IMGNET_STD),\n",
    "])\n",
    "\n",
    "tr_y_tsfm = transforms.Compose([\n",
    "    lambda np_2d: transforms.ToPILImage()(np_2d[:,:,None]),\n",
    "    TailPadder(PAD_OUT_SIZE, fill=FILL),\n",
    "    \n",
    "     # Data augs' geometric transforms only \n",
    "#      transforms.RandomRotation(RANDOM_ROT_DEGREE, fill=FILL),\n",
    "     lambda pil_y: torch.from_numpy(np.asarray(pil_y))\n",
    "])\n",
    "\n",
    "val_x_tsfm = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    TailPadder(PAD_OUT_SIZE, fill=FILL),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=IMGNET_MEAN, std=IMGNET_STD),\n",
    "])\n",
    "\n",
    "val_y_tsfm = transforms.Compose([\n",
    "    lambda np_2d: transforms.ToPILImage()(np_2d[:,:,None]),\n",
    "    TailPadder(PAD_OUT_SIZE, fill=FILL),\n",
    "     lambda pil_y: torch.from_numpy(np.asarray(pil_y))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Transformation + Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sample_train_ds = seg_ds.SegDataset(\n",
    "        ids_file=TRAIN_DATA_DIR/'sample_train_ids.txt', \n",
    "        x_dir=TRAIN_DATA_DIR/'images',\n",
    "        y_dir=TRAIN_DATA_DIR/'tf_segmentation',\n",
    "        transforms = [tr_x_tsfm, tr_y_tsfm],\n",
    "        verbose=True\n",
    ")\n",
    "\n",
    "sample_val_ds = seg_ds.SegDataset(\n",
    "        ids_file=TRAIN_DATA_DIR/'sample_val_ids.txt', \n",
    "        x_dir=TRAIN_DATA_DIR/'images',\n",
    "        y_dir=TRAIN_DATA_DIR/'tf_segmentation',\n",
    "        transforms = [val_x_tsfm, val_y_tsfm],\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_ds = seg_ds.SegDataset(\n",
    "        ids_file=TRAIN_DATA_DIR/'train_ids.txt', \n",
    "        x_dir=TRAIN_DATA_DIR/'images',\n",
    "        y_dir=TRAIN_DATA_DIR/'segmentations',\n",
    "        transforms = [tr_x_tsfm, tr_y_tsfm],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "val_ds = seg_ds.SegDataset(\n",
    "        ids_file=TRAIN_DATA_DIR/'val_ids.txt', \n",
    "        x_dir=TRAIN_DATA_DIR/'images',\n",
    "        y_dir=TRAIN_DATA_DIR/'segmentations',\n",
    "        transforms = [val_x_tsfm, val_y_tsfm],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "test_ds = seg_ds.SegDataset(\n",
    "    ids_file=TEST_DATA_DIR/'test_ids.txt',\n",
    "    x_dir=TEST_DATA_DIR/'images',\n",
    "    y_dir='',\n",
    "    get_label=False,\n",
    "    transforms = [val_x_tsfm, None],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 4. Transformed Dataset + Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bs = 16\n",
    "train_dl_params = {'batch_size': bs,\n",
    "                   'shuffle': True,\n",
    "#           'num_workers': 4\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sample_train_dl = DataLoader(sample_train_ds, **train_dl_params)\n",
    "sample_val_dl = DataLoader(sample_val_ds)\n",
    "sample_dataloaders = {\n",
    "    'train': sample_train_dl,\n",
    "    'val': sample_val_dl,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, **train_dl_params)\n",
    "val_dl = DataLoader(val_ds)\n",
    "test_dl = DataLoader(test_ds)\n",
    "dataloaders = {'train': train_dl,\n",
    "               'val': val_dl,\n",
    "               'test': test_dl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torchvision.models as tvmodels\n",
    "from model.fcn import fcn32s, get_fcn16, get_pretrained_fcn16\n",
    "from model.helpers import save_checkpt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from model.helpers import freeze_all, freeze_with_substr, unfreeze_all, get_frozen, get_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_classes = 21\n",
    "seed = 1\n",
    "pretrain=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = get_fcn16(device=DEVICE, seed=seed, pretrain=pretrain)\n",
    "## freeze all layers \n",
    "## replace the last classifier\n",
    "unfreeze_all(model.parameters())\n",
    "freeze_with_substr(model, 'conv_block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_names = []\n",
    "for p in model.named_parameters():\n",
    "    param_names.append(p[0])\n",
    "pprint(param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255, reduction='mean')\n",
    "# lr = 1e-5\n",
    "# weight_decay = 0.01\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 7. Learning Rate Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Exponentially increase learning rate at each iteration from a wide range (eg. 1e-8 to 1) to find a good max_lr for Cyclic Triangle Learning rate scheduling to be used for Train and Val loop \n",
    "- model: pretrained weights from VGG16\n",
    "    - CONV_BLOCKs are frozen\n",
    "- batch_size: 16\n",
    "- loss_fn uses (approximatedly) inverse_freq class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from scheduler.experiment import lr_range_test\n",
    "from scheduler.utils import get_mult_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# weighted loss function\n",
    "loss_weights = torch.from_numpy(np.array([0.025]+[1.]*(n_classes-1))).float().to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=loss_weights, ignore_index=255, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dl = train_dl\n",
    "max_lr = 1.\n",
    "min_lr = 1e-6\n",
    "n_epochs = 1\n",
    "n_iters = n_epochs * len(dl)\n",
    "mult_factor = get_mult_factor(min_lr, max_lr, n_iters)\n",
    "print(f'num of iters: {n_iters}, mult_factor: {mult_factor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model = get_fcn16(device=DEVICE, seed=seed, pretrain=pretrain)\n",
    "optimizer = optim.SGD(model.parameters(),lr=min_lr)\n",
    "lr_gen = optim.lr_scheduler.ExponentialLR(optimizer, gamma=mult_factor)\n",
    "\n",
    "beta = 0.3 #relative weight on old_average_loss\n",
    "lrs, losses, avg_losses = lr_range_test(model, dl, loss_fn, optimizer, lr_gen, DEVICE, n_iters=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hv.Curve(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hv.Curve(avg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lrs[70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## First round of training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- max_lr is determined from lr_range_test\n",
    "- using triangle, cyclic lr, train (+val) \n",
    "\n",
    "- model: pretrained fcn16\n",
    "- loss_fn: cross entropy with class weights\n",
    "- batch_size: 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from scheduler.cyclic import CyclicTLR\n",
    "from run import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dl = train_dl\n",
    "\n",
    "loss_weights = torch.from_numpy(np.array([0.025]+[1.]*(n_classes-1))).float().to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=loss_weights, ignore_index=255, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_lr = 0.021374546404928113 #lrs[70] #0.0124 0.007\n",
    "divide_factor = 3.\n",
    "min_lr = max_lr/divide_factor\n",
    "stepsize_in_epoch = 1\n",
    "stepsize =  stepsize_in_epoch * len(dl) # stepsize of lr-scheduler in iteration unit\n",
    "print('stepsize: ', stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_cycles = 30\n",
    "lr_test_epochs = (2*stepsize_in_epoch) * n_cycles\n",
    "print('total train epoch: ', lr_test_epochs)\n",
    "\n",
    "params = dict(max_epoch= lr_test_epochs,\n",
    "             batch_size=dl.batch_size,\n",
    "             fill_value=FILL)\n",
    "\n",
    "# Need to get a clean model\n",
    "model = get_fcn16(device=DEVICE, seed=seed, pretrain=pretrain)\n",
    "## freeze all layers, train the last classifier #todo: experiement with a clean classifier\n",
    "# unfreeze_all(model.parameters())\n",
    "freeze_with_substr(model, 'conv_block')\n",
    "# model = get_fcn16(device=DEVICE, seed=seed, pretrain=pretrain)\n",
    "optimizer = optim.SGD(model.parameters(),lr=min_lr)\n",
    "lr_scheduler = CyclicTLR(optimizer, min_lr, max_lr, stepsize)\n",
    "\n",
    "exp_lrs = []\n",
    "_, result = run(model, dataloaders, loss_fn, optimizer,\n",
    "                lr_scheduler, DEVICE, params, exp_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(\n",
    "#     hv.Curve(lrs) *\n",
    "    hv.Curve(result['train']['loss']) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_losses = result['train']['loss']\n",
    "train_accs = result['train']['acc']\n",
    "val_losses = result['val']['loss']\n",
    "val_accs = result['val']['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hv.Curve(result['train']['loss'])  * hv.Curve(result['val']['loss']).opts(color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Curve(result['train']['acc'])  \n",
    "    *\n",
    "    hv.Curve(result['val']['acc']).opts(color='red')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#debugging\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res = evaluate(model, val_dl, loss_fn, DEVICE, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Weighted loss function version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dl = train_dl\n",
    "loss_weights = torch.from_numpy(np.array([0.025]+[1.]*(n_classes-1))).float().to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=loss_weights, ignore_index=255, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_lr = 0.008\n",
    "divide_factor = 3.\n",
    "min_lr = max_lr/divide_factor\n",
    "stepsize_in_epoch = 1\n",
    "stepsize =  stepsize_in_epoch * len(dl) # stepsize of lr-scheduler in iteration unit\n",
    "print('stepsize: ', stepsize)\n",
    "\n",
    "n_cycles = 10\n",
    "lr_test_epochs = (2*stepsize_in_epoch) * n_cycles\n",
    "print('total train epoch: ', lr_test_epochs)\n",
    "\n",
    "params = dict(max_epoch= lr_test_epochs,\n",
    "             batch_size=dl.batch_size,\n",
    "             fill_value=FILL)\n",
    "\n",
    "model = get_fcn16(DEVICE, seed=1)\n",
    "optimizer = optim.SGD(model.parameters(),lr=min_lr)\n",
    "lr_scheduler = CyclicTLR(optimizer, min_lr, max_lr, stepsize)\n",
    "\n",
    "lrs = []\n",
    "_, result = run(model, dataloaders, loss_fn, optimizer,\n",
    "                lr_scheduler, DEVICE, params, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(\n",
    "#     hv.Curve(lrs) *\n",
    "    hv.Curve(result['train']['loss']) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_losses = result['train']['loss']\n",
    "train_accs = result['train']['acc']\n",
    "val_losses = result['val']['loss']\n",
    "val_accs = result['val']['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hv.Curve(result['train']['loss'])  * hv.Curve(result['val']['loss']).opts(color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Curve(result['train']['acc'])  \n",
    "#     *\n",
    "#     hv.Curve(result['val']['acc']).opts(color='red')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml_v2]",
   "language": "python",
   "name": "conda-env-earthml_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
