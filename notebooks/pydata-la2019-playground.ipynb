{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Experimental ML with Holoviews/Geoviews + PyTorch\n",
    "\n",
    "- type: PyData LA 2019 Proposal\n",
    "- date: 2019-09-21\n",
    "- author: Hayley Song (haejinso@usc.edu)\n",
    "- Prereq: \n",
    "    - Basic understanding of visaulization in python (eg. previously have used matplotlib.pyplot library)\n",
    "    - Basic understanding of neural network training process \n",
    "    I'll give a brief overview of the workflow, assuming audiences' previous experience with the following concepts\n",
    "        - mini-batch training\n",
    "        - forward-pass, backword-pass \n",
    "        - gradient, gradient descent algorithm\n",
    "        - classification, semantic segmentation\n",
    "        - image data stored as numpy ndarray\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "\n",
    "# Dashboards\n",
    "import param as pm, panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geoviews visualization default options\n",
    "H,W, = 250,250\n",
    "opts.defaults(\n",
    "    opts.RGB(height=H, width=W, tools=['hover'], active_tools=['wheel_zoom']),\n",
    "    opts.Image(height=H, width=W, tools=['hover'], active_tools=['wheel_zoom'], framewise=True ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Set up additional library path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "SP_ROOT = Path.home()/'Playground/ContextNet'\n",
    "SP_LIBS = SP_ROOT/'scripts' # to be changed to 'src'\n",
    "LIBS_DIR = Path('../src').absolute()\n",
    "DIRS_TO_ADD = [SP_LIBS, LIBS_DIR]\n",
    "for p in DIRS_TO_ADD:\n",
    "    assert p.exists()\n",
    "    \n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(f\"Added to sys.path: {p}\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint\n",
    "import SpacenetPath as spp\n",
    "import spacenet_globals as spg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 1: Explore your dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "city = 'vegas'\n",
    "rgb8_dir = spp.sample_rgb8_dirs[city]\n",
    "mask_dir = spp.sample_mask_dirs[city]\n",
    "sp_vec_dir = spp.sample_road_vec_dirs[city]\n",
    "osm_mask_dir = spp.sample_mask_dirs[city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rgb_fns = sorted([rgb8_dir/fn for fn in rgb8_dir.ls() if Path(fn).suffix in ['.tif', '.tiff']])\n",
    "mask_fns = sorted([mask_dir/fn for fn in mask_dir.ls() if Path(fn).suffix in ['.tif', '.tiff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for rgb_fn, mask_fn in zip(rgb_fns, mask_fns):\n",
    "    assert rgb_fn.exists() and mask_fn.exists()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_and_mask(idx):\n",
    "    for img_type, fns in dict(rgb=rgb_fns, mask=mask_fns):\n",
    "        da = xr.open_rasterio(fns[idx])\n",
    "        nc = len(da.band) #number of bands (ie. channels)\n",
    "        gv.RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "rgb_da = xr.open_rasterio(rgb_fns[idx])/255.\n",
    "mask_da = xr.open_rasterio(mask_fns[idx])/255.\n",
    "r,g,b = map(np.asarray,[rgb_da.sel(band=1), rgb_da.sel(band=2), rgb_da.sel(band=3)])\n",
    "xs, ys = np.array(rgb_da.coords['x']), np.array(rgb_da.coords['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_da.ndim, mask_da.dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_ds = rio.open(rgb_fns[idx])\n",
    "rgb_bounds = rgb_ds.bounds\n",
    "rgb_img = reshape_as_image(rgb_ds.read())/255.\n",
    "\n",
    "mask_ds = rio.open(mask_fns[idx])\n",
    "mask_bounds = ds.bounds\n",
    "mask_img = reshape_as_image(mask_ds.read())/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_rgb = hv.RGB(rgb_img, bounds=rgb_bounds, group='rgb').redim(x='Longitude', y='Latitude')\n",
    "hv_mask = hv.Image(mask_img, bounds=mask_bounds, group='mask').redim(x='Longitude', y='Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv_rgb + hv_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: `xarray.open_rasterio()` vs. `rasterio.open()`\n",
    "\n",
    "|||\n",
    "|---|---|\n",
    "|`xarray.open_rasterio()`| `rasterio.open()`|\n",
    "|it computes the coordinate points based on the `transform` matrix in the GeoTiff file| computes the `bounds` information upon metadata reading|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a dynamic map (~ callback)\n",
    "def get_hv_rgb(fn):\n",
    "    ds = rio.open(fn)\n",
    "    bounds = ds.bounds\n",
    "    img = reshape_as_image(ds.read())/255.\n",
    "    return hv.RGB(img, bounds=bounds).redim(x='Longitude', y='Latitude')\n",
    "# get_hv_rgb(rgb_fns[0])\n",
    "dmap = hv.DynamicMap(lambda fn: get_hv_rgb(fn), \n",
    "                     kdims=['fn'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it into a small gui\n",
    "\n",
    "class DataExplorer(pm.Parameterized):\n",
    "    rgb_fn = pm.Selector(rgb_fns)\n",
    "    mask_fn = pm.Selector(mask_fns)\n",
    "    mask_alpha = pm.Magnitude(0.5)\n",
    "    \n",
    "    @pm.depends('rgb_fn', watch=True)\n",
    "    def get_hv_rgb(self):\n",
    "        ds = rio.open(self.rgb_fn)\n",
    "        bounds = ds.bounds\n",
    "        img = reshape_as_image(ds.read())/255.\n",
    "        return hv.RGB(img, bounds=bounds, label='rgb').redim(x='Longitude', y='Latitude')\n",
    "    \n",
    "    @pm.depends('mask_fn', watch=True)\n",
    "    def get_hv_mask(self):\n",
    "        ds = rio.open(self.mask_fn)\n",
    "        bounds = ds.bounds\n",
    "        img = reshape_as_image(ds.read())/255.\n",
    "        return hv.Image(img, bounds=bounds, label='mask').redim(z='RT')\n",
    "    \n",
    "    @pm.depends('rgb_fn', watch=True)\n",
    "    def get_bounds(self):\n",
    "        ds = rio.open(self.rgb_fn)\n",
    "        xmin, ymin, xmax, ymax = ds.bounds\n",
    "        return hv.Div(\n",
    "            f\"\"\" \n",
    "            <h2>Bounds</h2>\n",
    "            <p>lon:{xmin, xmax},</p>\n",
    "            <p>lat: {ymin, ymax}</p>\"\"\")\n",
    "        \n",
    "        \n",
    "    def viewable(self):\n",
    "        dmap_rgb = hv.DynamicMap(self.get_hv_rgb).opts(show_legend=False)\n",
    "        dmap_mask = hv.DynamicMap(self.get_hv_mask)\n",
    "        opted = dmap_mask.apply.opts(alpha=self.param.mask_alpha)\n",
    "        \n",
    "        dmap_bounds = hv.DynamicMap(self.get_bounds)\n",
    "        return dmap_rgb * opted + dmap_bounds\n",
    "\n",
    "ex = DataExplorer()\n",
    "pn.Row(ex.param, ex.viewable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it into a small gui\n",
    "\n",
    "class ImagePairExplorer(pm.Parameterized):\n",
    "    rgb_fn = pm.Selector(rgb_fns)\n",
    "    mask_alpha = pm.Magnitude(0.5)\n",
    "    \n",
    "    @pm.depends('rgb_fn', watch=True)\n",
    "    def get_hv_rgb(self):\n",
    "        ds = rio.open(self.rgb_fn)\n",
    "        bounds = ds.bounds\n",
    "        img = reshape_as_image(ds.read())/255.\n",
    "        return hv.RGB(img, bounds=bounds, label='rgb').redim(x='Longitude', y='Latitude')\n",
    "    \n",
    "    @pm.depends('rgb_fn', watch=True)\n",
    "    def get_hv_mask(self):\n",
    "        mask_fn = get_sp_mask1300_fn(self.rgb_fn)\n",
    "        ds = rio.open(mask_fn)\n",
    "        bounds = ds.bounds\n",
    "        img = reshape_as_image(ds.read())/255.\n",
    "        return hv.Image(img, bounds=bounds, label='mask').redim(z='RT')\n",
    "    \n",
    "    @pm.depends('rgb_fn', watch=True)\n",
    "    def get_bounds(self):\n",
    "        ds = rio.open(self.rgb_fn)\n",
    "        xmin, ymin, xmax, ymax = ds.bounds\n",
    "        return hv.Div(\n",
    "            f\"\"\" \n",
    "            <h2>Bounds</h2>\n",
    "            <p>lon:{xmin, xmax},</p>\n",
    "            <p>lat: {ymin, ymax}</p>\"\"\")\n",
    "        \n",
    "    def viewable(self):\n",
    "        dmap_rgb = hv.DynamicMap(self.get_hv_rgb).opts(show_legend=False)\n",
    "        dmap_mask = hv.DynamicMap(self.get_hv_mask)\n",
    "        opted = dmap_mask.apply.opts(alpha=self.param.mask_alpha)\n",
    "        \n",
    "        dmap_bounds = hv.DynamicMap(self.get_bounds)\n",
    "        return dmap_rgb * opted + dmap_bounds\n",
    "\n",
    "ex = ImagePairExplorer()\n",
    "pn.Row(ex.param, ex.viewable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library introduction: `osmnx`\n",
    "- Refer to this [overview](https://github.com/gboeing/osmnx-examples/blob/master/notebooks/01-overview-osmnx.ipynb)\n",
    "- [Automating GIS](https://tinyurl.com/y6ncxg93)\n",
    "\n",
    "#### Main functions\n",
    "- Download road network data from OSM \n",
    "    - OSM stores data in EPSG:4326 CRS (ie. LAT/LON) \n",
    "    - `ox.graph_from_place`, `ox.graph_from_polygon`, `ox.graph_from_bbox`, `ox.graph_from_point`, and a couple more\n",
    "- Project the data to a proper UTM zone \n",
    "    - `ox.project_graph`\n",
    "    - useful when performing spatial computation in standard metrics (eg. distance between two points, area of a polygon)\n",
    "    - supports network analysis and basic geostatistics on the network \n",
    "- Plot the network graph for visualization\n",
    "    - `ox.plot_graph`\n",
    "- Save the figure \n",
    "    \n",
    "#### Useful function\n",
    "- Simply street network\n",
    "    - `ox.is_endpoint(G, node)`: checks if `node` is a valid intersection node in graph G (`valid` in the graph theoretical sense)\n",
    "    - `ox.simplify_graph(G)`: removes nodes that are not network nodes \n",
    "        - For example, in OSM, it's common to see multiple intermediate points along a curve line. These intermediate points are not real `nodes` in graph theoretic sense. `simplfy_graph` removes these nodes. See Part 3 of this [notebook](https://tinyurl.com/y53jcpw5)\n",
    "\n",
    "- Calculate basic network metrics\n",
    "    - `ox.basic_stats(G)`\n",
    "    - eg: `circuity_avg`\n",
    "        \n",
    "We are going to use `osmnx` to fetch the road network data from OSM of the regions we are interested in. Since `osmnx` utilizes caching on the downloaded area, it is better to download the data for the entire ROI, rather than doing so for each image tile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let add an action button to fetch osm roads\n",
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have `bounds` information, we are going to download the OSM data using `ox.graph_from_bbox` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = rgb_bounds\n",
    "north, south, east, west = bounds.top, bounds.bottom, bounds.right, bounds.left\n",
    "G1 = ox.graph_from_bbox(north, south, east, west, network_type='all') #'all_private'\n",
    "ox.plot_graph(G1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`G1`is a `networkx`'s `MultiDiGraph` object. We would like to look at the attributes of this network. For instance, what are the road type of each edge on the graph? The easiest way to inspect the attributes of the network is to convert the network into a `Geopandas.DataFrame` object.  Remember a graph is defined as a set of nodes and edges. So, when we convert the network graph into a DataFrame object, we extract nodes and edges information and store them into two distinct DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G1, nodes=True, edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on the edges (ie. the roads) for our tutorial. Notice that the Geopandas DataFrame (GPD) has a column called `geometry`. This column stores the geometry information of the road segment in `EPSG:4326` which is the spatial coordinate system used by OSM for storing data. Let's remove some columns that store metadata we are not going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges.drop(columns=['ref', 'service', 'u','v'], inplace=True)\n",
    "print(np.unique(gdf_edges.geom_type))\n",
    "gdf_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the `Geopandas.DataFrame` object, we can easily use `Geoviews` to visualize this road network. All the geometry objects are of type `LINESTRING`, so we are going to use `gv.Path` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_osm = gv.Path(gdf_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's overlay this on top of our Spacenet RGB and mask rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_rgb + hv_mask + gv_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 2: Monitor the training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 3: Interactively test your trained model on the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 4: What have the model learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 5: Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 6: Summary\n",
    "- Main Takeway\n",
    "\n",
    "- Resources\n",
    "    - General: \n",
    "        - Github repo for this talk:\n",
    "        - Holoviews:\n",
    "        - PyTorch:\n",
    "\n",
    "    - Data:\n",
    "        - Remote sensing data: google-earth-engine\n",
    "    - More from PyViz team:\n",
    "        - Link to scipy tutorials:\n",
    "        - Panel\n",
    "        - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "\n",
    "- Prepare your dataset: train, validation, test\n",
    "    - classification: \n",
    "        - eg: airplane/not-airplane, cat/dog/giraffe, land cover classifiation (forest, road, ...)\n",
    "        - eg: semantic segmentation: classify each pixel into a label in the label categories\n",
    "    This talk focuses on the semantic segmentation. So our dataset consists of the input image (RGB) and the target image which will be a \"mask\" image whose pixel has one of the labels in {'highway', 'track', 'dirt', 'others'}\n",
    "    \n",
    "    - clustering: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "===================\n",
    "PyCon Talk Proposal\n",
    "===================\n",
    "\n",
    ":Title: Experimental ML with PyViz + PyTorch\n",
    ":Duration: 30 min\n",
    ":Level: Intermediate\n",
    ":Categories: ?\n",
    "\n",
    "Summary\n",
    "=======\n",
    "\n",
    "Both newcomers and experienced developers alike love Python's built-in data types — especially dictionaries!  But how do dictionaries work? What do they do better than other container types, and where, on the other hand, are their weaknesses?  Using simple, vivid diagrams that show the secrets of how the dictionary is implemented, and a series of progressively interesting examples of its behavior, we will train the Python developer's mind to picture what the dictionary is doing in just enough detail to make good decisions, as your data sets get larger, about when to use dictionaries and when other data structures might be more appropriate.\n",
    "\n",
    "Description\n",
    "===========\n",
    "\n",
    "With some judicious use of ``ctypes``, one can write a Python routine\n",
    "that dissects a Python dictionary or set and displays its internals.\n",
    "Using such a tool — which I will also release on PyPI, to accompany the\n",
    "presentation slides — my presentation will show how dictionaries behave\n",
    "as you add items, overwrite them later, remove them, and iterate across\n",
    "the whole dictionary.\n",
    "\n",
    "By contemplating these normally hidden mechanics, and by showing some\n",
    "judicious results from the ``timeit`` module, both newcomers and\n",
    "experienced developers can gain new insight into the trade-offs that\n",
    "dictionaries provide between space and computational complexity,\n",
    "compared to the other alternatives in Python.  They will also understand\n",
    "why Python provides a ``hash()`` function; why user-defined classes are\n",
    "given the freedom to define their own hash function as well; and, what\n",
    "happens if they choose not to.\n",
    "\n",
    "The talk will actually discuss sets for most of its length, since they\n",
    "are simpler to diagram and understand, then show, at the end, how a\n",
    "dictionary is just a set with a second column, that holds a reference to\n",
    "an object stored at that key value.\n",
    "\n",
    "The talk will go something like this — each of the following 5 items,\n",
    "I'm imagining, will take up about five minutes (and probably five to ten\n",
    "slides) of my presentation, adding together to 25 minutes (leaving\n",
    "5 minutes left over for questions):\n",
    "\n",
    "1. Computer memory is like a Python list\n",
    "----------------------------------------\n",
    "\n",
    "Computer memory is indexed by integers, like Python lists (though the\n",
    "indexes tend to be much bigger!).  So a Python list is simple: it's an\n",
    "array of numbers, each indicating where in memory a Python object is\n",
    "stored, and Python can jump directly to list item *n*, but has to\n",
    "iterate across the whole list to find whether a particular item is in\n",
    "the list.\n",
    "\n",
    "An ordered list would let you find items more quickly, by jumping in\n",
    "halfway through, and then restricting your search to one half of the\n",
    "remaining list, just like looking for a name in a telephone book.  But,\n",
    "the cost would still grow as the list grew longer.  And, lists would be\n",
    "expensive to keep ordered!\n",
    "\n",
    "So, let's think about another plan.  In a normal list, items wind up at\n",
    "all sorts of indexes.  What if we created a list, and magically knew\n",
    "ahead of time exactly where each Python object belonged?  Then we could\n",
    "jump right to a given item, immediately, every time!\n",
    "\n",
    "2. The idea of a hash table\n",
    "---------------------------\n",
    "\n",
    "We would need a function, called a *hash function*, that when given a\n",
    "certain value — like the number 42, or the string ``\"Ni\"`` — always\n",
    "returns the same index.  Python provides this with a built-in called\n",
    "``hash()`` for which each built-in type provides an implementation.\n",
    "\n",
    "As an example, we will examine an empty ``set()`` — “look, it starts\n",
    "with space for eight items, even when it's empty!” — then we run\n",
    "``hash()`` on three simple Python values; then we insert them into the\n",
    "set, and see them land right at the indexes where ``hash()`` told them\n",
    "to.\n",
    "\n",
    "We now see the trade-off a hash table makes: in return for holding open\n",
    "several empty slots, and thus spending *memory*, it can find an item (or\n",
    "discover that it's absent) after only incurring the *static* cost of\n",
    "computing a hash.  With a few ``timeit`` tests, we determine how costly\n",
    "it is to compute a hash compared to two simple list operations: jumping\n",
    "directly to list item *n*, versus iterating across a small or large list\n",
    "to find an item.  Very small lists are very fast, but quickly become\n",
    "more expensive than computing the hash value to look in a set or\n",
    "dictionary.\n",
    "\n",
    "3. When indexes collide\n",
    "-----------------------\n",
    "\n",
    "The ``hash()`` function has to return a limited range of values for an\n",
    "unlimited range of inputs, so many objects *collide*.  I will create a\n",
    "collision in the set shown in the slides, and show how the hash table\n",
    "shunts aside the second item and puts it in a second spot that it can\n",
    "find it quickly again when we ask.  Removing the collision can still\n",
    "leave the other object stranded where it was put, so the cost of a\n",
    "collision can linger.\n",
    "\n",
    "When I add a fifth item to the set, it suddenly becomes 32 items long!\n",
    "This is to prevent collisions from piling up too deep; both the size of\n",
    "the hash table, *and* some of its behavior, are thus driven by the need\n",
    "to handle collisions.  I will note that, when a set or dictionary is\n",
    "re-sized, all of its contents are re-inserted, so that any junk left\n",
    "over gets periodically erased as long as the dictionary is occasionally\n",
    "growing or shrinking.\n",
    "\n",
    "I will show how the cost of re-allocating the whole hash table is\n",
    "reasonable if spread across many hundreds of set inserts, and also\n",
    "quickly show an animation of the dictionary growing, then shrinking as\n",
    "items are removed.  By showing some animations of how a dictionary\n",
    "\"looks\" as it grows and gets used, using some real-world data from\n",
    "observing a dictionary in one of my own applications, I will give a feel\n",
    "for how they behave in the wild.\n",
    "\n",
    "4. Providing your own hash function\n",
    "-----------------------------------\n",
    "\n",
    "The critical idea of giving one of your own classes its own\n",
    "``__hash__()`` method is whether each member of your class represents a\n",
    "*value* that could later — or even simultaneously — be represented by a\n",
    "different instance of your class.  I will show how we can easily create\n",
    "two floats with different ``id()`` but the same value (such that they\n",
    "satisfy Python equality), and show how they both go into the same\n",
    "dictionary slot because they have the same hash value.\n",
    "\n",
    "With a few examples and simple illustrations, I will show how simply\n",
    "calling ``hash()`` on the instance variables that give your class\n",
    "instance its own unique value, and combining their values together, you\n",
    "can create a decent hash for your own class.\n",
    "\n",
    "What if your class has no hash routine?  I will show how objects are\n",
    "then tested for uniqueness, rather than value, and how deleting and\n",
    "re-creating the \"same\" object gives it a different hash-table slot.\n",
    "\n",
    "5. The dictionary, and its alternatives\n",
    "---------------------------------------\n",
    "\n",
    "First, I finally show the dictionary in all of its glory: like a set, it\n",
    "keeps items in a hash table; but it adds a second column that for each\n",
    "key provides a \"value\".\n",
    "\n",
    "I will then show an animation of iteration across a dictionary: why the\n",
    "objects come out in random order, and why it's dangerous to modify the\n",
    "dictionary during iteration.\n",
    "\n",
    "Finally, I will briefly discuss alternatives.  If you want items back\n",
    "out in order, rather than having random access, use a ``heapq``.  If you\n",
    "only add and remove objects from the ends of a series, use a ``deque``.\n",
    "If you need both key-value referencing *and* ordering, then (for today)\n",
    "you might just use ``sorted()`` on your keys each time, or (in the\n",
    "future) use an ``OrderedDict``.\n",
    "\n",
    "But, for most uses, the List and Dictionary are king, and the audience\n",
    "will now hopefully understand why they're each perfect for their common\n",
    "uses.  “Any questions?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml]",
   "language": "python",
   "name": "conda-env-earthml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
